# Stellecta LucidAI Multi-LLM Backend

FastAPI backend implementing the Multi-LLM architecture for Stellecta.

## ğŸ—ï¸ Architecture

This backend implements the **Stellecta LucidAI Multi-LLM Architecture** with:

- **Multi-LLM Router**: Intelligent routing between LucidAI (proprietary) and external LLMs (Gemini, OpenAI, Claude)
- **Evaluation Service**: Multi-dimensional response quality scoring
- **Agent Layer**: Supervisor + 8 Mentor personas (Stella, Max, Nova, Darwin, Lexis, Neo, Luna, Atlas)
- **LVO Engine**: Learn-Verify-Own cycle (scaffold)
- **H-PEM Metrics**: Holistic Pedagogical Engagement Metrics (scaffold)
- **Gamification**: XP, achievements, streaks (scaffold)
- **Blockchain**: Stellar credential minting (stub)
- **Training Pipeline**: Anonymized data collection for LucidAI fine-tuning

## ğŸ“‹ Prerequisites

- Python 3.10+
- PostgreSQL 14+
- Redis (optional, for caching)

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 2. Configure Environment

```bash
cp .env.example .env
# Edit .env with your configuration
```

**Required Configuration:**
- `DATABASE_URL`: PostgreSQL connection string
- `GEMINI_API_KEY`: Google Gemini API key (default LLM for Phase 0)
- Optional: `OPENAI_API_KEY`, `ANTHROPIC_API_KEY`, `LUCIDAI_API_URL`

### 3. Initialize Database

```bash
# Run Alembic migrations
alembic upgrade head
```

### 4. Run the Server

```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

API will be available at: http://localhost:8000

**API Docs:**
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ agents/              # Agent Layer
â”‚   â”‚   â”œâ”€â”€ supervisor.py    # Supervisor Agent (orchestration)
â”‚   â”‚   â”œâ”€â”€ mentor_engine.py # Mentor Engine (8 personas)
â”‚   â”‚   â”œâ”€â”€ personas.py      # Mentor definitions
â”‚   â”‚   â””â”€â”€ schemas.py       # Agent schemas
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/                 # Multi-LLM Layer
â”‚   â”‚   â”œâ”€â”€ router.py        # Multi-LLM Router (CORE)
â”‚   â”‚   â”œâ”€â”€ evaluation.py    # Evaluation Service
â”‚   â”‚   â”œâ”€â”€ policies.py      # Routing Policies
â”‚   â”‚   â”œâ”€â”€ base.py          # BaseLLMClient (abstraction)
â”‚   â”‚   â”œâ”€â”€ schemas.py       # LLM schemas
â”‚   â”‚   â””â”€â”€ providers/       # LLM Providers
â”‚   â”‚       â”œâ”€â”€ lucidai.py   # LucidAI (stub)
â”‚   â”‚       â”œâ”€â”€ gemini.py    # Gemini (active)
â”‚   â”‚       â”œâ”€â”€ openai.py    # OpenAI GPT-4
â”‚   â”‚       â””â”€â”€ claude.py    # Claude 3.5
â”‚   â”‚
â”‚   â”œâ”€â”€ lvo/                 # Learn-Verify-Own Engine (scaffold)
â”‚   â”‚   â”œâ”€â”€ service.py       # LVO Orchestrator
â”‚   â”‚   â””â”€â”€ hpem.py          # H-PEM Calculator
â”‚   â”‚
â”‚   â”œâ”€â”€ gamification/        # Gamification Engine (scaffold)
â”‚   â”‚   â””â”€â”€ service.py       # XP, achievements, streaks
â”‚   â”‚
â”‚   â”œâ”€â”€ blockchain/          # Stellar Blockchain (stub)
â”‚   â”‚   â””â”€â”€ service.py       # Credential minting
â”‚   â”‚
â”‚   â”œâ”€â”€ training/            # Training Data Pipeline
â”‚   â”‚   â”œâ”€â”€ logger.py        # LLM Interaction Logger
â”‚   â”‚   â”œâ”€â”€ anonymization.py # COPPA/GDPR anonymization
â”‚   â”‚   â”œâ”€â”€ labeling.py      # Automated labeling
â”‚   â”‚   â””â”€â”€ dataset.py       # Dataset builder
â”‚   â”‚
â”‚   â”œâ”€â”€ database/            # Database Layer
â”‚   â”‚   â”œâ”€â”€ engine.py        # SQLAlchemy engine
â”‚   â”‚   â”œâ”€â”€ models/          # Database models
â”‚   â”‚   â”‚   â”œâ”€â”€ student.py
â”‚   â”‚   â”‚   â”œâ”€â”€ conversation.py
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_interaction.py      # NEW
â”‚   â”‚   â”‚   â”œâ”€â”€ training_example.py     # NEW
â”‚   â”‚   â”‚   â”œâ”€â”€ model_version.py        # NEW
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_performance_tracking.py  # NEW
â”‚   â”‚   â”‚   â”œâ”€â”€ hpem.py
â”‚   â”‚   â”‚   â”œâ”€â”€ gamification.py
â”‚   â”‚   â”‚   â””â”€â”€ blockchain.py
â”‚   â”‚   â””â”€â”€ repositories/
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                 # FastAPI Routers
â”‚   â”‚   â”œâ”€â”€ chat.py          # Chat endpoint
â”‚   â”‚   â”œâ”€â”€ agents.py        # Agent info
â”‚   â”‚   â””â”€â”€ admin.py         # Admin/metrics
â”‚   â”‚
â”‚   â”œâ”€â”€ config.py            # Configuration (Pydantic Settings)
â”‚   â””â”€â”€ main.py              # FastAPI app entry point
â”‚
â”œâ”€â”€ alembic/                 # Database Migrations
â”œâ”€â”€ tests/                   # Tests
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ .env.example             # Example environment variables
â””â”€â”€ README.md                # This file
```

## ğŸ”‘ Key Components

### 1. Multi-LLM Router

**File:** `app/llm/router.py`

Central orchestration for all LLM interactions:
- Routes requests to appropriate LLM (LucidAI, Gemini, OpenAI, Claude)
- Handles single/dual/hybrid execution modes
- Evaluates and selects best responses
- Logs all interactions for training

**Usage:**
```python
from app.llm.router import MultiLLMRouter
from app.llm.schemas import LLMRequest

router = MultiLLMRouter()
request = LLMRequest(
    system_prompt="You are a helpful tutor...",
    user_message="How do I solve 2x + 3 = 7?",
    temperature=0.7,
)
response = await router.generate(request, context={})
```

### 2. Evaluation Service

**File:** `app/llm/evaluation.py`

Multi-dimensional quality scoring:
- Correctness (0-1)
- Didactic Quality (0-1)
- Persona Alignment (0-1)
- Safety (0-1)
- Curriculum Alignment (0-1)

### 3. Agent Layer

**Files:** `app/agents/supervisor.py`, `app/agents/mentor_engine.py`

- **Supervisor Agent**: Orchestrates all interactions (safety, mentor selection, quality validation)
- **Mentor Engine**: 8 personas (Stella, Max, Nova, Darwin, Lexis, Neo, Luna, Atlas)

### 4. LLM Providers

All providers implement `BaseLLMClient`:
- **LucidAI** (stub): Proprietary model (Phase 2)
- **Gemini** (active): Default for Phase 0
- **OpenAI**: GPT-4 Turbo
- **Claude**: Claude 3.5 Sonnet

## ğŸ§ª Testing

```bash
# Run tests
pytest

# Run with coverage
pytest --cov=app --cov-report=html
```

## ğŸ“Š Database Schema

### New Tables (Multi-LLM Architecture)

- **`llm_interactions`**: All LLM requests/responses with routing metadata
- **`training_examples`**: Anonymized training data for LucidAI
- **`model_versions`**: LucidAI model registry
- **`llm_performance_tracking`**: Confidence calibration data

### Existing Tables

- `students`, `conversations`, `conversation_messages`
- `hpem_scores`, `gamification_progress`, `blockchain_credentials`

## ğŸ” Security & Privacy

- **COPPA/GDPR Compliant**: All training data anonymized
- **PII Scrubbing**: Automatic removal of personal information
- **API Key Management**: All secrets in environment variables
- **Rate Limiting**: TODO (Phase 2)

## ğŸ“ˆ Monitoring

**LLM Metrics:**
```bash
curl http://localhost:8000/api/admin/llm-metrics
```

Returns:
- Total requests per LLM
- Average latency
- Cost tracking
- Quality scores

## ğŸš§ TODO (Future Phases)

- [ ] Full LVO business logic implementation
- [ ] H-PEM calculation algorithms
- [ ] Gamification mechanics
- [ ] Stellar blockchain integration
- [ ] LucidAI model fine-tuning
- [ ] RLHF training pipeline
- [ ] Advanced evaluation models
- [ ] Real-time confidence calibration

## ğŸ“š Documentation

Full architecture documentation: See `stellecta-lucidai-multi-llm-architecture.md`

## ğŸ¤ Contributing

This backend is part of the Stellecta platform. All changes must:
- Follow the **extension-not-replacement** principle
- Maintain vendor-agnostic design
- Include tests
- Update documentation

## ğŸ“„ License

Proprietary - Stellecta Platform
